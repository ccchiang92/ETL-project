{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Raw Data from Johns Hopkins\n",
    "# By Chris Chiang\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '../raw_data/Johns_Hopkins_day_by_day/'\n",
    "# Setting up dates\n",
    "start_date = dt.date(2020, 1, 22)\n",
    "last_date = dt.date(2020, 3, 27)\n",
    "# country format changed for the last 6 days of data so need to adjust\n",
    "days = (last_date - start_date).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China data not found on 2020-01-22\n",
      "Korea, South data not found on 2020-01-22\n",
      "Republic of Korea data not found on 2020-01-22\n",
      "China data not found on 2020-01-23\n",
      "Korea, South data not found on 2020-01-23\n",
      "Republic of Korea data not found on 2020-01-23\n",
      "China data not found on 2020-01-24\n",
      "Korea, South data not found on 2020-01-24\n",
      "Republic of Korea data not found on 2020-01-24\n",
      "China data not found on 2020-01-25\n",
      "Korea, South data not found on 2020-01-25\n",
      "Republic of Korea data not found on 2020-01-25\n",
      "China data not found on 2020-01-26\n",
      "Korea, South data not found on 2020-01-26\n",
      "Republic of Korea data not found on 2020-01-26\n",
      "China data not found on 2020-01-27\n",
      "Korea, South data not found on 2020-01-27\n",
      "Republic of Korea data not found on 2020-01-27\n",
      "China data not found on 2020-01-28\n",
      "Korea, South data not found on 2020-01-28\n",
      "Republic of Korea data not found on 2020-01-28\n",
      "China data not found on 2020-01-29\n",
      "Korea, South data not found on 2020-01-29\n",
      "Republic of Korea data not found on 2020-01-29\n",
      "China data not found on 2020-01-30\n",
      "Korea, South data not found on 2020-01-30\n",
      "Republic of Korea data not found on 2020-01-30\n",
      "China data not found on 2020-01-31\n",
      "Korea, South data not found on 2020-01-31\n",
      "Republic of Korea data not found on 2020-01-31\n",
      "China data not found on 2020-02-01\n",
      "Korea, South data not found on 2020-02-01\n",
      "Republic of Korea data not found on 2020-02-01\n",
      "China data not found on 2020-02-02\n",
      "Korea, South data not found on 2020-02-02\n",
      "Republic of Korea data not found on 2020-02-02\n",
      "China data not found on 2020-02-03\n",
      "Korea, South data not found on 2020-02-03\n",
      "Republic of Korea data not found on 2020-02-03\n",
      "China data not found on 2020-02-04\n",
      "Korea, South data not found on 2020-02-04\n",
      "Republic of Korea data not found on 2020-02-04\n",
      "China data not found on 2020-02-05\n",
      "Korea, South data not found on 2020-02-05\n",
      "Republic of Korea data not found on 2020-02-05\n",
      "China data not found on 2020-02-06\n",
      "Korea, South data not found on 2020-02-06\n",
      "Republic of Korea data not found on 2020-02-06\n",
      "China data not found on 2020-02-07\n",
      "Korea, South data not found on 2020-02-07\n",
      "Republic of Korea data not found on 2020-02-07\n",
      "China data not found on 2020-02-08\n",
      "Korea, South data not found on 2020-02-08\n",
      "Republic of Korea data not found on 2020-02-08\n",
      "China data not found on 2020-02-09\n",
      "Korea, South data not found on 2020-02-09\n",
      "Republic of Korea data not found on 2020-02-09\n",
      "China data not found on 2020-02-10\n",
      "Korea, South data not found on 2020-02-10\n",
      "Republic of Korea data not found on 2020-02-10\n",
      "China data not found on 2020-02-11\n",
      "Korea, South data not found on 2020-02-11\n",
      "Republic of Korea data not found on 2020-02-11\n",
      "China data not found on 2020-02-12\n",
      "Korea, South data not found on 2020-02-12\n",
      "Republic of Korea data not found on 2020-02-12\n",
      "China data not found on 2020-02-13\n",
      "Korea, South data not found on 2020-02-13\n",
      "Republic of Korea data not found on 2020-02-13\n",
      "China data not found on 2020-02-14\n",
      "Korea, South data not found on 2020-02-14\n",
      "Republic of Korea data not found on 2020-02-14\n",
      "China data not found on 2020-02-15\n",
      "Korea, South data not found on 2020-02-15\n",
      "Republic of Korea data not found on 2020-02-15\n",
      "China data not found on 2020-02-16\n",
      "Korea, South data not found on 2020-02-16\n",
      "Republic of Korea data not found on 2020-02-16\n",
      "China data not found on 2020-02-17\n",
      "Korea, South data not found on 2020-02-17\n",
      "Republic of Korea data not found on 2020-02-17\n",
      "China data not found on 2020-02-18\n",
      "Korea, South data not found on 2020-02-18\n",
      "Republic of Korea data not found on 2020-02-18\n",
      "China data not found on 2020-02-19\n",
      "Korea, South data not found on 2020-02-19\n",
      "Republic of Korea data not found on 2020-02-19\n",
      "China data not found on 2020-02-20\n",
      "Korea, South data not found on 2020-02-20\n",
      "Republic of Korea data not found on 2020-02-20\n",
      "China data not found on 2020-02-21\n",
      "Korea, South data not found on 2020-02-21\n",
      "Republic of Korea data not found on 2020-02-21\n",
      "China data not found on 2020-02-22\n",
      "Korea, South data not found on 2020-02-22\n",
      "Republic of Korea data not found on 2020-02-22\n",
      "China data not found on 2020-02-23\n",
      "Korea, South data not found on 2020-02-23\n",
      "Republic of Korea data not found on 2020-02-23\n",
      "China data not found on 2020-02-24\n",
      "Korea, South data not found on 2020-02-24\n",
      "Republic of Korea data not found on 2020-02-24\n",
      "China data not found on 2020-02-25\n",
      "Korea, South data not found on 2020-02-25\n",
      "Republic of Korea data not found on 2020-02-25\n",
      "China data not found on 2020-02-26\n",
      "Korea, South data not found on 2020-02-26\n",
      "Republic of Korea data not found on 2020-02-26\n",
      "China data not found on 2020-02-27\n",
      "Korea, South data not found on 2020-02-27\n",
      "Republic of Korea data not found on 2020-02-27\n",
      "China data not found on 2020-02-28\n",
      "Korea, South data not found on 2020-02-28\n",
      "Republic of Korea data not found on 2020-02-28\n",
      "China data not found on 2020-02-29\n",
      "Korea, South data not found on 2020-02-29\n",
      "Republic of Korea data not found on 2020-02-29\n",
      "China data not found on 2020-03-01\n",
      "Korea, South data not found on 2020-03-01\n",
      "Republic of Korea data not found on 2020-03-01\n",
      "China data not found on 2020-03-02\n",
      "Korea, South data not found on 2020-03-02\n",
      "Republic of Korea data not found on 2020-03-02\n",
      "China data not found on 2020-03-03\n",
      "Korea, South data not found on 2020-03-03\n",
      "Republic of Korea data not found on 2020-03-03\n",
      "China data not found on 2020-03-04\n",
      "Korea, South data not found on 2020-03-04\n",
      "Republic of Korea data not found on 2020-03-04\n",
      "China data not found on 2020-03-05\n",
      "Korea, South data not found on 2020-03-05\n",
      "Republic of Korea data not found on 2020-03-05\n",
      "China data not found on 2020-03-06\n",
      "Korea, South data not found on 2020-03-06\n",
      "Republic of Korea data not found on 2020-03-06\n",
      "China data not found on 2020-03-07\n",
      "Korea, South data not found on 2020-03-07\n",
      "Republic of Korea data not found on 2020-03-07\n",
      "China data not found on 2020-03-08\n",
      "Korea, South data not found on 2020-03-08\n",
      "Republic of Korea data not found on 2020-03-08\n",
      "China data not found on 2020-03-09\n",
      "Korea, South data not found on 2020-03-09\n",
      "Republic of Korea data not found on 2020-03-09\n",
      "South Korea data not found on 2020-03-10\n",
      "China data not found on 2020-03-10\n",
      "Korea, South data not found on 2020-03-10\n",
      "South Korea data not found on 2020-03-11\n",
      "Republic of Korea data not found on 2020-03-11\n",
      "South Korea data not found on 2020-03-12\n",
      "Republic of Korea data not found on 2020-03-12\n",
      "Mainland China data not found on 2020-03-13\n",
      "South Korea data not found on 2020-03-13\n",
      "Republic of Korea data not found on 2020-03-13\n",
      "Mainland China data not found on 2020-03-14\n",
      "South Korea data not found on 2020-03-14\n",
      "Republic of Korea data not found on 2020-03-14\n",
      "Mainland China data not found on 2020-03-15\n",
      "South Korea data not found on 2020-03-15\n",
      "Republic of Korea data not found on 2020-03-15\n",
      "Mainland China data not found on 2020-03-16\n",
      "South Korea data not found on 2020-03-16\n",
      "Republic of Korea data not found on 2020-03-16\n",
      "Mainland China data not found on 2020-03-17\n",
      "South Korea data not found on 2020-03-17\n",
      "Republic of Korea data not found on 2020-03-17\n",
      "Mainland China data not found on 2020-03-18\n",
      "South Korea data not found on 2020-03-18\n",
      "Republic of Korea data not found on 2020-03-18\n",
      "Mainland China data not found on 2020-03-19\n",
      "South Korea data not found on 2020-03-19\n",
      "Republic of Korea data not found on 2020-03-19\n",
      "Mainland China data not found on 2020-03-20\n",
      "South Korea data not found on 2020-03-20\n",
      "Republic of Korea data not found on 2020-03-20\n",
      "Mainland China data not found on 2020-03-21\n",
      "South Korea data not found on 2020-03-21\n",
      "Republic of Korea data not found on 2020-03-21\n",
      "Mainland China data not found on 2020-03-22\n",
      "South Korea data not found on 2020-03-22\n",
      "Republic of Korea data not found on 2020-03-22\n",
      "Mainland China data not found on 2020-03-23\n",
      "South Korea data not found on 2020-03-23\n",
      "Republic of Korea data not found on 2020-03-23\n",
      "Mainland China data not found on 2020-03-24\n",
      "South Korea data not found on 2020-03-24\n",
      "Republic of Korea data not found on 2020-03-24\n",
      "Mainland China data not found on 2020-03-25\n",
      "South Korea data not found on 2020-03-25\n",
      "Republic of Korea data not found on 2020-03-25\n",
      "Mainland China data not found on 2020-03-26\n",
      "South Korea data not found on 2020-03-26\n",
      "Republic of Korea data not found on 2020-03-26\n",
      "Mainland China data not found on 2020-03-27\n",
      "South Korea data not found on 2020-03-27\n",
      "Republic of Korea data not found on 2020-03-27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>Total</td>\n",
       "      <td>279384.0</td>\n",
       "      <td>14150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>9332.0</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>81897.0</td>\n",
       "      <td>3296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>Italy</td>\n",
       "      <td>86498.0</td>\n",
       "      <td>9134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>US</td>\n",
       "      <td>101657.0</td>\n",
       "      <td>1581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Total</td>\n",
       "      <td>549.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>547.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Country/Region  Confirmed   Deaths\n",
       "331  2020-03-27           Total   279384.0  14150.0\n",
       "330  2020-03-27     South Korea     9332.0    139.0\n",
       "329  2020-03-27  Mainland China    81897.0   3296.0\n",
       "328  2020-03-27           Italy    86498.0   9134.0\n",
       "327  2020-03-27              US   101657.0   1581.0\n",
       "..          ...             ...        ...      ...\n",
       "4    2020-01-22           Total      549.0     17.0\n",
       "3    2020-01-22           Italy        0.0      0.0\n",
       "2    2020-01-22     South Korea        1.0      0.0\n",
       "1    2020-01-22  Mainland China      547.0     17.0\n",
       "0    2020-01-22              US        1.0      0.0\n",
       "\n",
       "[332 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forloop init\n",
    "current_date = start_date\n",
    "combine_df = pd.DataFrame()\n",
    "# i is the index of combine_df\n",
    "i = 0\n",
    "\n",
    "for day in range(int(days)+1):\n",
    "    # convert date into string and load in csv\n",
    "    load_string = current_date.strftime(\"%m-%d-%Y\")\n",
    "    try:\n",
    "        today_df = pd.read_csv(data_loc + load_string +\n",
    "                               '.csv').groupby('Country/Region')\n",
    "    except:\n",
    "        # deal with data column format change\n",
    "        today_df = pd.read_csv(data_loc + load_string +\n",
    "                               '.csv').groupby('Country_Region')\n",
    "    # total count init\n",
    "    day_deaths_tot = 0\n",
    "    day_confirmed_tot = 0\n",
    "    # Loop through intrested countries\n",
    "    for needed in ['US', 'Mainland China', 'South Korea', 'Italy', 'China', 'Korea, South', 'Republic of Korea']:\n",
    "        try:\n",
    "            needed_df = today_df.get_group(needed)\n",
    "            day_deaths_tot += needed_df['Deaths'].sum()\n",
    "            day_confirmed_tot += needed_df['Confirmed'].sum()\n",
    "            # write rows base on country\n",
    "            # handle all South Korea formats\n",
    "            if needed in ['South Korea', 'Korea, South', 'Republic of Korea']:\n",
    "                row = pd.DataFrame({'Date': current_date, 'Country/Region': 'South Korea',\n",
    "                                    'Confirmed': needed_df['Confirmed'].sum(), 'Deaths': needed_df['Deaths'].sum()}, index=[i])\n",
    "            # handle All China formats\n",
    "            elif needed in ['China', 'Mainland China']:\n",
    "                row = pd.DataFrame({'Date': current_date, 'Country/Region': 'Mainland China',\n",
    "                                    'Confirmed': needed_df['Confirmed'].sum(), 'Deaths': needed_df['Deaths'].sum()}, index=[i])\n",
    "            else:\n",
    "                # Italy and US rows\n",
    "                row = pd.DataFrame({'Date': current_date, 'Country/Region': needed,\n",
    "                                    'Confirmed': needed_df['Confirmed'].sum(), 'Deaths': needed_df['Deaths'].sum()}, index=[i])\n",
    "            # add row into full df\n",
    "            combine_df = pd.concat([row, combine_df])\n",
    "            i += 1\n",
    "        except KeyError:\n",
    "            # catch missing data\n",
    "            # No Italy Data for first few days so store 0\n",
    "            if needed == 'Italy':\n",
    "                row = pd.DataFrame(\n",
    "                    {'Date': current_date, 'Country/Region': needed, 'Confirmed': 0, 'Deaths': 0}, index=[i])\n",
    "                combine_df = pd.concat([row, combine_df])\n",
    "                i += 1\n",
    "            else:\n",
    "                print(f'{needed} data not found on {current_date}')\n",
    "        # add total row\n",
    "    row = pd.DataFrame({'Date': current_date, 'Country/Region': 'Total',\n",
    "                        'Confirmed': day_confirmed_tot, 'Deaths': day_deaths_tot}, index=[i])\n",
    "    combine_df = pd.concat([row, combine_df])\n",
    "    i += 1\n",
    "    # increment date\n",
    "    current_date = current_date + dt.timedelta(days=1)\n",
    "combine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df.to_csv('../cleaned_data/cases.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-22 no Italy\n",
      "2020-01-23 no Italy\n",
      "2020-01-24 no Italy\n",
      "2020-01-25 no Italy\n",
      "2020-01-26 no Italy\n",
      "2020-01-27 no Italy\n",
      "2020-01-28 no Italy\n",
      "2020-01-29 no Italy\n",
      "2020-01-30 no Italy\n"
     ]
    }
   ],
   "source": [
    "# just some testing script below\n",
    "\n",
    "# testing for missing data rows\n",
    "start_date = dt.date(2020, 1, 22)\n",
    "current_date = start_date\n",
    "for day in range(int(days)+1):\n",
    "    today_df = combine_df.groupby('Date').get_group(current_date)\n",
    "    day_sum = 0\n",
    "    for korea in ['South Korea']:\n",
    "        day_sum += today_df.groupby('Country/Region').get_group(korea)[\n",
    "            'Confirmed'].sum()\n",
    "    if day_sum == 0:\n",
    "        print(f'{current_date} no korea')\n",
    "    day_sum = 0\n",
    "    for korea in ['Italy']:\n",
    "        day_sum += today_df.groupby('Country/Region').get_group(korea)[\n",
    "            'Confirmed'].sum()\n",
    "    if day_sum == 0:\n",
    "        print(f'{current_date} no Italy')\n",
    "    day_sum = 0\n",
    "    for korea in ['US']:\n",
    "        day_sum += today_df.groupby('Country/Region').get_group(korea)[\n",
    "            'Confirmed'].sum()\n",
    "    if day_sum == 0:\n",
    "        print(f'{current_date} no US')\n",
    "    day_sum = 0\n",
    "    for korea in ['Mainland China']:\n",
    "        day_sum += today_df.groupby('Country/Region').get_group(korea)[\n",
    "            'Confirmed'].sum()\n",
    "    if day_sum == 0:\n",
    "        print(f'{current_date} no China')\n",
    "\n",
    "    current_date = current_date + dt.timedelta(days=1)\n",
    "# Only the first few days of Italy are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda6b55c75a92594a4496380a81f2f453fd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
